{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec(Skip_Gram/CBow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['왕', '매우', '완강', '기', '호랑이', '강한', '남자']\n",
      "1. Similar word with 왕자: \n",
      " [('수학', 0.15638932585716248), ('하면서', 0.13214828073978424), ('호랑이', 0.1067313477396965), ('완강', 0.09508532285690308), ('현명한', 0.06804552674293518), ('강한', 0.04469199478626251), ('남자', 0.03923055902123451), ('공주', 0.029929019510746002), ('여왕', 0.027665594592690468), ('공부', 0.017946943640708923)]\n",
      "2. Embedding of 왕자 shape: \n",
      " (128,)\n",
      "3. Similarity of 왕자, 남자: \n",
      " 0.039230555295944214\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# input (list of list of str) : A list of tokenized sentences used as input to the Word2Vec model.\n",
    "# example: [[\"왕\", \"통치\", \"잘하다\"],[\"여왕\", \"민생\", \"살리다\"]]\n",
    "cleaned_corpus= ['왕 매우 완강 기 호랑이 강한 남자',\n",
    "                    '여왕 현명한 예쁜 여자',\n",
    "                    '소년 젊은 남자',\n",
    "                    '소녀 젊은 예쁜 수학 공부 하면서 즐기는 여자',\n",
    "                    '왕자 젊고 현명한 왕 것',\n",
    "                    '공주 젊고 예쁜 현명한 여왕 것',\n",
    "                    '남자 강하다',\n",
    "                    '여자 예쁘다',\n",
    "                    '왕자 왕 소년',\n",
    "                    '공주 왕비 소녀']\n",
    "input = [text.split() for text in cleaned_corpus]\n",
    "print(input[0])\n",
    "model = Word2Vec(\n",
    "    sentences=input,\n",
    "    vector_size=128, # The dimensionality of the word vectors\n",
    "    sg=1,  # Skip-gram = 1 / Cbow = 0\n",
    "    negative=5,  # The number of negative samples to use for negative sampling(default = 5)\n",
    "    min_count=1, # Ignores all words with a frequency lower than this value(default = 1)\n",
    "    workers=4, # Number of worker threads for training (default = 4)\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "word_1 = \"왕자\"\n",
    "word_2 = \"남자\"\n",
    "print(f\"1. Similar word with {word_1}: \\n {model.wv.most_similar(word_1)}\")\n",
    "print(f\"2. Embedding of {word_1} shape: \\n {model.wv[word_1].shape}\")\n",
    "print(f\"3. Similarity of {word_1}, {word_2}: \\n {model.wv.similarity(word_1, word_2) }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_module_3_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
